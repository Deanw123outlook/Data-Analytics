{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c33197",
   "metadata": {},
   "source": [
    "## Microsoft Azure Logging\n",
    "\n",
    "NOTE\n",
    "\n",
    "This was commercial work completed to help build out tooling for proactive infastrucutre analysis and problem detection from Microsoft Azure data. The dataset used has been generated in Microsfot Excel to mirror close to the original quantitative data. Furthermore, categorical naming and datetime data has been changed.\n",
    "\n",
    "#### SYSTEM INFASTRUCTURE BACKGROUND\n",
    "\n",
    "The specific type of logging indicates the servers hit by client traffic/requests for subject specific information to be returned across Microsoft Azure Cloud Infastructure. Specific clients will be aligned with Azure clusters/engine-nodes. Cluster will hold include certain engine nodes at different periods in time dependent on customer/client traffic expectations.\n",
    "\n",
    "\n",
    "#### Server \n",
    "\n",
    "We will not desribe the particular servers functionality in this case. However, what is import to understand is that the serves which are assigned to specific nodes in this instance were being hit to return in house functionality. This Python script will not detail this functionality. What is important is the usecase of the code to pull out specific information from our data.\n",
    "\n",
    "Using our logging tooling we can acquire upto 15 days logs for specific system infastructure logging aimed at both proactive and reactive problem detection and solution.\n",
    "\n",
    "Data\n",
    "\n",
    "- Date : log date\n",
    "- EngineNode : Specific engine node used across & assinged to specific clusters for specific clients\n",
    "- Client : Live client customer\n",
    "- RequestSize(TB) : Custumer|Client Server Request Size (Memory) - Terabytes\n",
    "- Milliseconds : Time milliseconds to return functionality to customer\n",
    "- Seconds : Time seconds to return functionality to customer\n",
    "- Minutes : Time minutes to return functionality to customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379587ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # import numpy package for numerical python\n",
    "import pandas as pd # import pandas\n",
    "\n",
    "# import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px \n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#\n",
    "from collections import Counter, OrderedDict\n",
    "from operator import itemgetter   \n",
    "\n",
    "from sklearn.preprocessing import normalize, StandardScaler # data pre-processing libraries and modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dc832d",
   "metadata": {},
   "source": [
    "Python Collections Module: https://www.geeksforgeeks.org/python-collections-module/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756f95cd",
   "metadata": {},
   "source": [
    "#### DATA CLEANING AND FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4745d7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataframe from CSV file & parse dates\n",
    "data = pd.read_excel('DataDecodedPrepared.xlsx', parse_dates = True)\n",
    "\n",
    "#create copy of orginal dataframe\n",
    "data_copy = data.copy(deep = True)\n",
    "\n",
    "# drop column\n",
    "data.drop(data.columns[[6]], axis=1, inplace=True)\n",
    "\n",
    "# strng strip (remove part of string)\n",
    "data['Milliseconds'] = data['Milliseconds'].str.rstrip('ms')\n",
    "# remove white space\n",
    "data['Client'] = data['Client'].str.strip()\n",
    "data['EngineNode'] = data['EngineNode'].str.strip()\n",
    "\n",
    "#covert 'Date' column object to datetime object\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "#\n",
    "data['Milliseconds'] = data['Milliseconds'].astype('int64')\n",
    "\n",
    "#new column milliseconds conversion to seconds\n",
    "data['Seconds'] = data['Milliseconds']/1000\n",
    "\n",
    "#new column seconds conversion to minutes\n",
    "data['Minutes'] = data['Milliseconds']/60000\n",
    "\n",
    "# new column include log alert\n",
    "data['AlertFrequency'] = data.index + 1 #  dataframe index, integer numbers or string values, column labels(column names), usually strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75006892",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3294932a",
   "metadata": {},
   "source": [
    "#### LOG FREQUENCY\n",
    "\n",
    "We will need to count each alert (len(df)) as an individual alert which is the case, however in this dataset we do not have this specific column/series data. We can do this with further feature engineering be creating a new column and using the index to increment the value of the index on each iteration by 1 using the dataframe. \n",
    "\n",
    "NOTE\n",
    "\n",
    "Its important to remember zero indexing for this task.\n",
    "\n",
    "VISUALIZATION\n",
    "\n",
    "Simply, we can then plot this quantitative discrete data against time using our datetime column in the pandas dataframe. We will be using a histogram to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b21b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using plotly express line plot we can visualize the distrubtion of the quantitive discrete data over time\n",
    "fig = px.histogram(data_frame = data, x = 'Date', y = 'AlertFrequency',color_discrete_sequence=['red'],\n",
    "                   opacity=0.6, width=1000, height=500 ,histnorm=\"probability\")\n",
    "#\n",
    "fig.update_layout(\n",
    "    margin=dict(l=20, r=20, t=20, b=20),\n",
    "    paper_bgcolor=\"LightSteelBlue\",\n",
    ")\n",
    "#\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5987d8",
   "metadata": {},
   "source": [
    "In terms of subject matter this is highly important information as we can see when our Azure clsuer/nodes were under most constraint within this time period. This can then be cross analysed against further findings below. \n",
    "\n",
    "For example later in our script we will be analysing engine node and specific server (function) returned in seconds. If we see trends such as spikes in the earlier dates this would coincide with the above findings. However, if we are seeing trend spikes in returned server functions in the latter periods this potentially could indicate a deeper problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c182b9",
   "metadata": {},
   "source": [
    "#### DESCRIPTIVE STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d118cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266eb227",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17b4c7d",
   "metadata": {},
   "source": [
    "### Engine Node Analysis\n",
    "In this section of our script we will cut into our dataset to pull out useful information. This will be done by data wrangling and datavisualization techniques. Through this we can gather useful insights into our Engine nodes performance. Commercially this was extremely useful information to build into tooling.\n",
    "\n",
    "DATA ANALYSIS TASKS\n",
    "- Visualize client count in this dataset\n",
    "- Visualize the server return time via lineplot acrooss time for keyAzure Engine Nodes\n",
    "- Visualize the data where metrics are above certain values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d5504",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,7))\n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(x = data['Client'], data = data)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show ()\n",
    "#\n",
    "display(data['Client'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f8a19c",
   "metadata": {},
   "source": [
    "NOTE\n",
    "\n",
    "For our next this has been quiet difficult to find a method for the particular functionality we want. We need to seperate the key engine nodes into seperate isolated dataframes to maintain all data across all columns. The reason we need this is it has been easier to work with our data in the coming tasks. There was difficulty pre-defining variables followed by using ising method an subestting the data.\n",
    "\n",
    "Will continue to search for a better method ! However, the below code returns what is needed for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc17bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting based on categorical data (Pandas isin method)\n",
    "en_5 = data['EngineNode'].isin([\"engine5\"])  # isin() method checks if the Dataframe contains the specified value(s) returns boolean values\n",
    "en_5 = data[en_5] # subset data\n",
    "#\n",
    "en_1 = data['EngineNode'].isin([\"engine1\"])\n",
    "en_1 = data[en_1]\n",
    "#\n",
    "en_0 = data['EngineNode'].isin([\"engine0\"])\n",
    "en_0 = data[en_0]\n",
    "#\n",
    "en_3 = data['EngineNode'].isin([\"engine3\"])\n",
    "en_3 = data[en_3]\n",
    "#\n",
    "en_4 = data['EngineNode'].isin([\"engine4\"])\n",
    "en_4 = data[en_4]\n",
    "#\n",
    "en_9 = data['EngineNode'].isin([\"engine9\"])\n",
    "en_9 = data[en_9]\n",
    "#\n",
    "en_2 = data['EngineNode'].isin([\"engine2\"])\n",
    "en_2 = data[en_2]\n",
    "#\n",
    "en_6 = data['EngineNode'].isin([\"engine6\"])\n",
    "en_6 = data[en_6]\n",
    "#\n",
    "en_8 = data['EngineNode'].isin([\"engine8\"])\n",
    "en_8 = data[en_8]\n",
    "#\n",
    "en_7 = data['EngineNode'].isin([\"engine7\"])\n",
    "en_7 = data[en_7]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8449ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Line Plots (Subplots) using matplotlib\n",
    "plt.style.use('ggplot')\n",
    "fig, ax = plt.subplots(10, figsize = (10,18), sharey= False)\n",
    "fig.suptitle('Server Return Time Seconds Engine Engine Node Analysis')\n",
    "\n",
    "#\n",
    "ax[0].plot(en_5['Date'], en_5['Seconds'], color = 'g', alpha = 0.4)\n",
    "ax[1].plot(en_1['Date'], en_1['Seconds'], color = 'r', alpha = 0.4)\n",
    "ax[2].plot(en_0['Date'], en_0['Seconds'], color = 'b', alpha = 0.4)\n",
    "ax[3].plot(en_3['Date'], en_3['Seconds'], color = 'g', alpha = 0.4)\n",
    "ax[4].plot(en_4['Date'], en_4['Seconds'], color = 'r', alpha = 0.4)\n",
    "ax[5].plot(en_9['Date'], en_9['Seconds'], color = 'g', alpha = 0.4)\n",
    "ax[6].plot(en_2['Date'], en_2['Seconds'], color = 'r', alpha = 0.4)\n",
    "ax[7].plot(en_6['Date'], en_6['Seconds'], color = 'b', alpha = 0.4)\n",
    "ax[8].plot(en_8['Date'], en_8['Seconds'], color = 'g', alpha = 0.4)\n",
    "ax[9].plot(en_7['Date'], en_7['Seconds'], color = 'r', alpha = 0.4)\n",
    "\n",
    "#Set xlabe;s\n",
    "ax[0].set_xlabel('Date')\n",
    "ax[1].set_xlabel('Date')\n",
    "ax[2].set_xlabel('Date')\n",
    "ax[3].set_xlabel('Date')\n",
    "ax[4].set_xlabel('Date')\n",
    "ax[5].set_xlabel('Date')\n",
    "ax[6].set_xlabel('Date')\n",
    "ax[7].set_xlabel('Date')\n",
    "ax[8].set_xlabel('Date')\n",
    "ax[9].set_xlabel('Date')\n",
    "\n",
    "#set y labels\n",
    "ax[0].set_ylabel('Engine Node 5')\n",
    "ax[1].set_ylabel('Engine Node 1')\n",
    "ax[2].set_ylabel('Engine Node 0')\n",
    "ax[3].set_ylabel('Engine Node 3')\n",
    "ax[4].set_ylabel('Engine Node 4')\n",
    "ax[5].set_ylabel('Engine Node 9')\n",
    "ax[6].set_ylabel('Engine Node 2')\n",
    "ax[7].set_ylabel('Engine Node 6')\n",
    "ax[8].set_ylabel('Engine Node 8')\n",
    "ax[9].set_ylabel('Engine Node 7')\n",
    "\n",
    "#Set spacing\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3971b931",
   "metadata": {},
   "source": [
    "When we cross analyse our alert distrubiton over this time period, this would coincide the drop of in latter days we see in load on the engine nodes. This is measured in our peviosu log frequency visualization. We can see clearly from our visualization that the load is less than starting dates here on our top nodes. Please refer to the log frequency alert to make cross compaarisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004fbf18",
   "metadata": {},
   "source": [
    "## Engine Node | > RequestSize(TB) Terabytes | > Average Seconds | Time Taken \n",
    "For this part of our analysis we will be cross analysing 15 nodes based on their value counts in this dataframe. These nodes are considered under highest constraint during this timeframe from our previous analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ba9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tope nodes\n",
    "display(data['EngineNode'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting based on categorical data (Pandas isin method)\n",
    "top_nodes = data['EngineNode'].isin(['engine5','engine1','engine0','engine3','engine4','engine9','engine2'])\n",
    "top_nodes = data[top_nodes]\n",
    "#\n",
    "key_nodes = top_nodes[np.logical_and(top_nodes['RequestSize(TB)'] > 10, top_nodes['Seconds'] > 9)]\n",
    "key_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genrate pie chart categorized by clients\n",
    "fig = px.pie(key_nodes, values='Seconds', names='Client',title='-')\n",
    "#\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "#\n",
    "# Update title and height\n",
    "fig.update_layout(height=700, width=1000,\n",
    "                  title_text=\"TOP Engine Nodes | > Average Request Size (TB)| Seconds > (average seconds) | Time Taken Returned Functionality \")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76c4719d",
   "metadata": {},
   "source": [
    "#\n",
    "n5 = en_5.groupby(['Client'])['Seconds'].agg([max,sum])\n",
    "n5 = n5.reset_index() # reset index\n",
    "#\n",
    "n1 = en_1.groupby(['Client'])['Seconds'].agg([max])\n",
    "n1 = n1.reset_index() # reset index\n",
    "#\n",
    "n0 = en_0.groupby(['Client'])['Seconds'].agg([max])\n",
    "n0 = n0.reset_index() # reset index\n",
    "#\n",
    "n3 = en_3.groupby(['Client'])['Seconds'].agg([max])\n",
    "n3 = n3.reset_index() # reset index\n",
    "#\n",
    "n4 = en_4.groupby(['Client'])['Seconds'].agg([max])\n",
    "n4 = n4.reset_index() # reset index\n",
    "#\n",
    "n9 = en_9.groupby(['Client'])['Seconds'].agg([max])\n",
    "n9 = n9.reset_index() # reset index\n",
    "#\n",
    "n2 = en_2.groupby(['Client'])['Seconds'].agg([max])\n",
    "n2 = n2.reset_index() # reset index\n",
    "#\n",
    "n6 = en_6.groupby(['Client'])['Seconds'].agg([max])\n",
    "n6 = n6.reset_index() # reset index\n",
    "#\n",
    "n8 = en_8.groupby(['Client'])['Seconds'].agg([max])\n",
    "n8 = n8.reset_index() # reset index\n",
    "#\n",
    "n7 = en_7.groupby(['Client'])['Seconds'].agg([max])\n",
    "n7 = n7.reset_index() # reset index\n",
    "\n",
    "# inout above data into dictionary and import into pandas dataframe\n",
    "Dictionary = {'Node_5':n5['Client'],'Node_1':n1['Client'],'Node_0':n0['Client'],'Node_3':n3['Client'],'Node_4':n4['Client'],'Node_9':n9['Client'],\n",
    "              'Node_2':n2['Client'],'Node_6':n6['Client'],'Node_8':n8['Client'],'Node_7':n7['Client']}\n",
    "df = pd.DataFrame(Dictionary) # dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea588bf2",
   "metadata": {},
   "source": [
    "# Export above dataframe to Excel\n",
    "df.to_excel(r'C:\\Users\\dean.watters\\Documents\\Product Support\\Product Support\\Projects\\Price Found Emergency.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "716af9b0",
   "metadata": {},
   "source": [
    "empty_list = [] # initiate empty list\n",
    "#\n",
    "for n,engine in price['EngineNode'].iteritems(): # iteritems() method generates an iterator object of the DataFrame, allowing us to iterate each column of the DataFrame\n",
    "    empty_list.append(engine)\n",
    "\n",
    "# add data to -> convert list to counter data structure to count string occurence in list\n",
    "collection = Counter(empty_list) # casting\n",
    "\n",
    "# add data to -> convert data stucture counter into dictionary\n",
    "engine_dict = dict(collection) # casting\n",
    "engine_dict = OrderedDict(sorted(engine_dict.items(), key = itemgetter(1), reverse = True))\n",
    "\n",
    "engine = [] # initiate empty list\n",
    "occurence = [] # initiate empty list\n",
    "for key, value in engine_dict.items():\n",
    "    if value >= 2078:\n",
    "        engine.append(key) # append method will add items to list\n",
    "        occurence.append(value)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e5670dd",
   "metadata": {},
   "source": [
    "# figure size\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "# define Seaborn color palette to use\n",
    "palette_color = sns.color_palette('bright')\n",
    "  \n",
    "# plotting data on chart\n",
    "plt.pie(occurence, labels=engine, colors=palette_color, autopct='%.0f%%')\n",
    "\n",
    "# Title\n",
    "plt.title('--')\n",
    "  \n",
    "# displaying chart\n",
    "plt.show(), price['EngineNode'].value_counts().head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
